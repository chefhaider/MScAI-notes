

use multiple n classifiers  
the more classifiers we pick the lower majority being wrong would be true

with enough data we can dependently train enough weak classifiers

- finding multiple local minimas and saving them for ensembling
- take model checkpoints, used during training and later use them for ensemblng
-  moving average of weights can generate new ensembles
- can also try different methodes

